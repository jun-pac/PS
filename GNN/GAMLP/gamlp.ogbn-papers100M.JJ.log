WARNING:root:The OGB package is out of date. Your version is 1.3.5, while the latest version is 1.3.6.
Namespace(act='sigmoid', alpha=0.5, att_drop=0.0, batch_size=5000, bns=True, dataset='ogbn-papers100M', dropout=0.5, eval_every=1, gama=0.5, gpu=0, hidden=1024, input_drop=0.0, jjnorm=True, label_drop=0.0, label_num_hops=9, lr=0.001, method='R_GAMLP_RLU', n_layers_1=4, n_layers_2=6, n_layers_3=4, node_emb_path='./ogbn-papers100M-jj.node-emb', num_hops=6, num_runs=3, patience=300, pre_dropout=False, pre_process=True, residual=False, root='./dataset', seed=0, stages=[100, 150, 150, 150], temp=0.001, threshold=0.0, train_num_epochs=[0, 0, 0, 0], use_rlu=True, weight_decay=0)
Run 0 start training
name : ogbn-papers100M
# Nodes: 111059956
# Edges: 1615685872
# Train: 1207179
# Val: 125265
# Test: 214338
# Classes: 172

Graph(num_nodes=111059956, num_edges=1615685872,
      ndata_schemes={'year': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(128,), dtype=torch.float32)}
      edata_schemes={})
{'year': tensor([[2012],
        [2013],
        [1988],
        ...,
        [2020],
        [1997],
        [2020]]), 'feat': tensor([[-0.4340, -0.3536, -0.3905,  ...,  0.1789, -0.2058, -0.0182],
        [-0.2557,  0.0541,  0.1021,  ..., -0.1388, -0.2668, -0.2331],
        [-0.0451,  0.2022, -0.0104,  ...,  0.0784, -0.0793, -0.1480],
        ...,
        [-0.0997, -0.0583, -0.3169,  ...,  0.2028, -0.1163, -0.0872],
        [-0.0938, -0.1223, -0.0225,  ...,  0.1683,  0.0074, -0.2471],
        [-0.1233,  0.1898,  0.0079,  ...,  0.3472, -0.0503, -0.1539]])}
paper_year.shape : torch.Size([111059956, 1])
paper_year.dtype : torch.int64
g.num_nodes : <bound method DGLHeteroGraph.num_nodes of Graph(num_nodes=111059956, num_edges=1615685872,
      ndata_schemes={'year': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(128,), dtype=torch.float32)}
      edata_schemes={})>
New graph generated! : 15.8833
172
paper_year.dtype ; torch.int64
paper_year.shape ; torch.Size([111059956])
labels.dtype ; torch.int64
labels.shape ; torch.Size([111059956])
Compute 1th neighbor-averaged labels... 0.0000
Compute 2th neighbor-averaged labels... 103.9538
Compute 3th neighbor-averaged labels... 181.3719
Compute 4th neighbor-averaged labels... 255.2153
Compute 5th neighbor-averaged labels... 339.1821
Compute 6th neighbor-averaged labels... 426.6366
Compute 7th neighbor-averaged labels... 502.6561
Compute 8th neighbor-averaged labels... 576.0339
Compute 9th neighbor-averaged labels... 656.7074
len, max, min of train_nid ; torch.Size([1207179]) 111052523, 602
len, max, min of val_nid ; torch.Size([125265]) 110996715, 57698
len, max, min of test_nid ; torch.Size([214338]) 111059953, 43768
first ten train_nid : 
tensor(602, device='cuda:0')
tensor(684, device='cuda:0')
tensor(1384, device='cuda:0')
tensor(1525, device='cuda:0')
tensor(2127, device='cuda:0')
tensor(2184, device='cuda:0')
tensor(2205, device='cuda:0')
tensor(3965, device='cuda:0')
tensor(4200, device='cuda:0')
tensor(5031, device='cuda:0')
first ten valid_nid : 
tensor(57698, device='cuda:0')
tensor(145220, device='cuda:0')
tensor(599977, device='cuda:0')
tensor(692549, device='cuda:0')
tensor(730071, device='cuda:0')
tensor(787610, device='cuda:0')
tensor(790194, device='cuda:0')
tensor(852706, device='cuda:0')
tensor(885742, device='cuda:0')
tensor(968113, device='cuda:0')
first ten test_nid : 
tensor(43768, device='cuda:0')
tensor(122141, device='cuda:0')
tensor(251239, device='cuda:0')
tensor(458801, device='cuda:0')
tensor(503557, device='cuda:0')
tensor(671042, device='cuda:0')
tensor(1068741, device='cuda:0')
tensor(1416999, device='cuda:0')
tensor(1848797, device='cuda:0')
tensor(1884478, device='cuda:0')
use rlu
R_GAMLP_RLU(
  (prelu): PReLU(num_parameters=1)
  (lr_att): Linear(in_features=2048, out_features=1, bias=True)
  (lr_output): FeedForwardNetII(
    (layers): ModuleList(
      (0): Dense(
        (bias): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): GraphConvolution(
        (bias): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): GraphConvolution(
        (bias): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): GraphConvolution(
        (bias): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): GraphConvolution(
        (bias): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): Dense(
        (bias): BatchNorm1d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (prelu): PReLU(num_parameters=1)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (process): ModuleList(
    (0): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (1): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (2): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (3): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (4): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (5): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (6): FeedForwardNet(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (bns): ModuleList(
        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (prelu): PReLU(num_parameters=1)
      (dropout): Dropout(p=0.5, inplace=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (input_drop): Dropout(p=0.0, inplace=False)
  (att_drop): Dropout(p=0.0, inplace=False)
  (res_fc): Linear(in_features=128, out_features=1024, bias=True)
  (label_drop): Dropout(p=0.0, inplace=False)
  (label_fc): FeedForwardNet(
    (layers): ModuleList(
      (0): Linear(in_features=172, out_features=1024, bias=True)
      (1): Linear(in_features=1024, out_features=1024, bias=True)
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Linear(in_features=1024, out_features=172, bias=True)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prelu): PReLU(num_parameters=1)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (act): Sigmoid()
)
# Params: 16308751
Epoch 0, Time(s): 38.5236,Train loss: 0.0026, Train acc: 70.4446 
Epoch 1, Time(s): 29.1490,Train loss: 0.0018, Train acc: 85.3133 Epoch 1, Time(s): 30.4168, Val 0.6436, Best Epoch 1,Val 0.6436, Test 0.6061
Epoch 2, Time(s): 25.3848,Train loss: 0.0014, Train acc: 88.9738 Epoch 2, Time(s): 26.2130, Val 0.6377, Best Epoch 1,Val 0.6436, Test 0.6061
Epoch 3, Time(s): 21.9225,Train loss: 0.0012, Train acc: 90.5644 Epoch 3, Time(s): 22.8608, Val 0.6024, Best Epoch 1,Val 0.6436, Test 0.6061
Epoch 4, Time(s): 23.3720,Train loss: 0.0010, Train acc: 91.5042 Epoch 4, Time(s): 24.3468, Val 0.6232, Best Epoch 1,Val 0.6436, Test 0.6061
Epoch 5, Time(s): 21.1854,Train loss: 0.0011, Train acc: 92.1286 Epoch 5, Time(s): 22.0495, Val 0.6037, Best Epoch 1,Val 0.6436, Test 0.6061
Epoch 6, Time(s): 22.2306,Train loss: 0.0009, Train acc: 92.6275 Epoch 6, Time(s): 23.2193, Val 0.5901, Best Epoch 1,Val 0.6436, Test 0.6061
